{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5772b792",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Imágenes - Modelo CNN Melanoma\n",
    "\n",
    "Este notebook muestra cómo usar el módulo de preprocesamiento para preparar las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f95a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Montar Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dfb8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar src al path\n",
    "sys.path.append('/content/drive/MyDrive/TIC_CNN_Modelo_Melanoma')\n",
    "\n",
    "from src.data import create_data_generators, create_data_flow_from_dataframe\n",
    "from src.config.config import CSV_SPLIT_FOLDER, BATCH_SIZE, IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b970a8",
   "metadata": {},
   "source": [
    "## 1. Cargar los datasets divididos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los CSVs generados anteriormente\n",
    "train_df = pd.read_csv(os.path.join(CSV_SPLIT_FOLDER, \"train.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(CSV_SPLIT_FOLDER, \"val.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(CSV_SPLIT_FOLDER, \"test.csv\"))\n",
    "\n",
    "print(f\"Train: {len(train_df)} imágenes\")\n",
    "print(f\"Val: {len(val_df)} imágenes\")\n",
    "print(f\"Test: {len(test_df)} imágenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07178571",
   "metadata": {},
   "source": [
    "## 2. Crear generadores de datos\n",
    "\n",
    "Los generadores aplican:\n",
    "- **Train**: Augmentation (rotación, zoom, flips) + Normalización ImageNet\n",
    "- **Val/Test**: Solo normalización ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen, val_test_datagen = create_data_generators()\n",
    "\n",
    "print(\"Generadores creados:\")\n",
    "print(f\"  - Train: con augmentation\")\n",
    "print(f\"  - Val/Test: solo normalización\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4fa17d",
   "metadata": {},
   "source": [
    "## 3. Crear flujos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = create_data_flow_from_dataframe(\n",
    "    train_datagen, \n",
    "    train_df, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = create_data_flow_from_dataframe(\n",
    "    val_test_datagen, \n",
    "    val_df, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = create_data_flow_from_dataframe(\n",
    "    val_test_datagen, \n",
    "    test_df, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\nFlujos creados con batch_size={BATCH_SIZE}\")\n",
    "print(f\"Train steps per epoch: {len(train_generator)}\")\n",
    "print(f\"Val steps per epoch: {len(val_generator)}\")\n",
    "print(f\"Test steps: {len(test_generator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc103c",
   "metadata": {},
   "source": [
    "## 4. Visualizar ejemplos de augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b462dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener un batch de entrenamiento\n",
    "sample_batch_x, sample_batch_y = next(train_generator)\n",
    "\n",
    "# Visualizar 8 imágenes con augmentation\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(8):\n",
    "    # Denormalizar para visualización (aproximado)\n",
    "    img = sample_batch_x[i]\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"Label: {int(sample_batch_y[i])}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Ejemplos de imágenes con augmentation (Train)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626593a",
   "metadata": {},
   "source": [
    "## 5. Verificar forma de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04639bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Forma del batch de imágenes: {sample_batch_x.shape}\")\n",
    "print(f\"Forma del batch de etiquetas: {sample_batch_y.shape}\")\n",
    "print(f\"Target size configurado: {IMAGE_SIZE}\")\n",
    "print(f\"\\nRango de valores después de preprocesamiento:\")\n",
    "print(f\"  Min: {sample_batch_x.min():.2f}\")\n",
    "print(f\"  Max: {sample_batch_x.max():.2f}\")\n",
    "print(f\"  Mean: {sample_batch_x.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072cb5d",
   "metadata": {},
   "source": [
    "## 6. Ejemplo de preprocesamiento individual (para inferencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import load_and_preprocess_image\n",
    "\n",
    "# Tomar una imagen de ejemplo\n",
    "example_path = train_df['filepath'].iloc[0]\n",
    "print(f\"Procesando: {example_path}\")\n",
    "\n",
    "# Preprocesar para inferencia\n",
    "processed_img = load_and_preprocess_image(example_path)\n",
    "\n",
    "print(f\"\\nForma procesada: {processed_img.shape}\")\n",
    "print(f\"Lista para modelo: {processed_img.shape == (1, *IMAGE_SIZE, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ba3b6",
   "metadata": {},
   "source": [
    "## 7. (Opcional) Limpieza de artefactos\n",
    "\n",
    "Ejemplo de eliminación de pelos usando morfología."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c99b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import preprocess_with_cleaning\n",
    "import cv2\n",
    "\n",
    "# Cargar imagen original\n",
    "example_img = cv2.imread(example_path)\n",
    "example_img = cv2.cvtColor(example_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Procesar con limpieza\n",
    "cleaned_img = preprocess_with_cleaning(example_path)\n",
    "\n",
    "# Visualizar comparación\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].imshow(cv2.resize(example_img, IMAGE_SIZE))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Denormalizar para visualización\n",
    "cleaned_display = cleaned_img[0]\n",
    "cleaned_display = (cleaned_display - cleaned_display.min()) / (cleaned_display.max() - cleaned_display.min())\n",
    "axes[1].imshow(cleaned_display)\n",
    "axes[1].set_title('Con limpieza de artefactos')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
